# KnoxQuack

_KnoxQuack es proyecto en el cu√°l se pueden realizar busquedas de informaci√≥n sobre los lanzamientos de videojuegos, de manera que al introducir el nombre de un videojuego, el programa te devolvera la caratula de dicho juego, la informaci√≥n general de este y una peque√±a aportaci√≥n de rese√±as positivas y negativas sobre este mismo, esto esta pensado para que el usuario sea consciente si realmente le merece la pena o no de adquirir dicho producto._

##  2. Obtenci√≥n de los datos, limpieza y descripci√≥n 

##  3. Exploraci√≥n y visualizaci√≥n de los datos 

De los datos almacenados podemos contar los siguientes registros:

* 11000 juegos 
* alrededor de 55000 reviews 
* alrededor de 40000 usuarios 

La informaci√≥n para cada juego se presenta en la p√°gina con la informaci√≥n disponible del juego:

![Captura desde 2023-03-12 16-34-37](https://user-images.githubusercontent.com/116188406/224555440-01e87d88-7149-4028-8e76-b732123bc4b5.png)

Para facilitar la exposici√≥n tambi√©n se ha facilitado una tabla con el n√∫mero de reviews hechas por un √∫nico usuario siempre 
que estas sean mayor a 5. Se ha decidido as√≠ porque el algoritmo trabaja mucho mejor cuantas m√°s reviews se han hecho aunque 
no siempre da los mismos datos de afinidad ya que hay usuarios que tan solo punt√∫an los juegos que no le gustan con 0 u otros 
que punt√∫an con muchos 10. 

![Captura desde 2023-03-12 16-40-06](https://user-images.githubusercontent.com/116188406/224555713-bdafc0cc-fc26-4fce-a58e-d9687e826a72.png)

Tambi√©n se pueden ver directamente en la p√°gina las reviews que han hecho esos usuarios y de la exploraci√≥n, como puede observarse en la 
captura de abajo, hay usuarios que puntuaron varias veces el mismo juego. No se trata en este caso de duplicados sino de reviews distintas
realizadas en fechas diferentes del mismo juego, probablemente por cambios de opini√≥n o errores. Ser√≠a interesante arrojar m√°s luz a este 
detalle y puede ser √∫til para otros modelos de ML pero no era necesario para el desarrollo del sistema de recomendaci√≥n. 

![Captura desde 2023-03-12 16-40-06](https://user-images.githubusercontent.com/116188406/224555975-b6bcec95-8933-43b3-8190-b3696b6e180a.png)



##  4. Preparaci√≥n de los datos para los algoritmos de Machine Learning 

Para el desarrollo de este sistema de recomendaci√≥n hemos usado `spark` en su vers√≠on `3.2.3` Este procedimiento puede verse en el cuaderno 
de [Google Colab](https://colab.research.google.com/drive/1GhP9Fg4NEvbYbyqJa-ggkU5qzY09ti5G) que tambi√©n se adjunta en este proyecto en la carpeta `recommendation_model` ser√°n necesarios los archivos `games.json` y `reviews_data.json`, disponibles en el datalake `metacritic_scrape`.

El cuaderno viene con todo el proceso de instalaci√≥n y configuraci√≥n para que `spark` funcione. Es necesario mencionar que el lenguaje nativo 
de`spark` es `java`:coffee:, por lo que para su uso en `python`:snake: se usa `pyspark`. Para que no de problemas esta librer√≠a debe 
instalarse en la misma versi√≥n que la de spark. Adem√°s tambi√©n es necesario configurar las variables de entorno con las rutas a donde se encuentran
tanto `spark` como la m√°quina virtual de `java`, en este caso en su versi√≥n 8. Tambi√©n usaremos, la librer√≠a de spark `mlib` que viene preparada 
con multitud de algoritmos listos para ser usados. 

![Captura desde 2023-03-12 16-54-49](https://user-images.githubusercontent.com/116188406/224556412-3d224be7-7504-4205-86cf-d35084678ce8.png)

Con `spark` podemos convertir f√°cilmente y r√°pidamente nuestros archivos `json` en dataframes que se presentan en formatos tabulares. 

![Captura desde 2023-03-12 17-03-25](https://user-images.githubusercontent.com/116188406/224557015-9d43683b-79d3-48c3-8201-47702988c43e.png)

Podemos visualizar tambi√©n los tipos de datos que tenemos en nuestro dataframe puede usarse `printSchema()` es importante usar esta funci√≥n 
porque debemos asegurarnos que todo lo que le pasamos al algoritmo sean datos num√©ricos. 

![Captura desde 2023-03-12 17-04-11](https://user-images.githubusercontent.com/116188406/224557069-04935de9-8a8f-4f39-9838-fc0b22096dd0.png)

Seleccionamos los campos que vamos a necesitar para pas√°rselos al algoritmo para entrenamiento, al que le pasaremos los datos de las reviews `user_id`,
`game_id` y `score`

![Captura desde 2023-03-12 17-08-04](https://user-images.githubusercontent.com/116188406/224557358-9f363ebf-bc94-4386-8c0c-09578a2582fe.png)

Por √∫ltimo antes de pasar al entrenamiento nos aseguramos de que todos los datos que tenemos sean num√©ricos

![Captura desde 2023-03-12 17-10-23](https://user-images.githubusercontent.com/116188406/224557413-195dac18-a549-48cd-a677-82c1ed637183.png)


##  5. Entrenamiento del modelo y resultados 

Para este caso, se ha decidido utlizar un algoritmo de recomendaci√≥n llamado `Alternating Least Squares` o `ALS` para los amigos. Este algoritmo realiza
como todos, operaciones de productos de matrices para tratar de estimar una puntuaci√≥n y est√° pensado espec√≠ficamente para usuarios, productos 
y puntuaciones. En un experimento realizado hace algunas semanas dio buenos resultados para los datos de puntuaciones de pel√≠culas de imdb. Este 
algoritmo adem√°s es usado por grandes compa√±√≠as como Netflix o Amazon entre otras. 

Tambi√©n se consider√≥ el algoritmo `a priori` disponible en la librer√≠a de `apyori` de `python`, funcionaba bien para datos de cestas de la compra 
pero no hubo tiempo de probarlo, pues la implementaci√≥n de este sistema se comi√≥ gran parte del tiempo de este proyecto. 

Para entrenar el modelo se le pasa el n√∫mero m√°ximo de iteraciones `maxIter`, par√°metro de regularizaci√≥n `regParam`, `userCol` la columna 
que contiene los datos de usuario, `itemCol` la columna que contiene los datos de producto y por √∫ltimo la columna de puntuaci√≥n, `ratingCol`
si los datos son n√∫mericos nuestro modeloy los datos no son aleatorios no dar√° errores. Esto √∫ltimo es importante seg√∫n recoge la propia 
[documentaci√≥n de spark para ALS](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.recommendation.ALS.html) en la 
que asegura que datos no deterministas pueden causar errores. 

![Captura desde 2023-03-12 17-28-55](https://user-images.githubusercontent.com/116188406/224558347-a65de9d8-5eb7-4384-8823-56a19ab3af12.png)

En este caso no tenemos una manera de asegurar que nuestros datos son correctos con datos de test de validaci√≥n ya que los gustos personales
a fin de cuentas son arbitrarios y ni siquiera muchas veces los propios sistemas de recomendaci√≥n de las grandes compa√±√≠as aciertan. En realidad
estos algoritmos se basan casi siempre en la premisa de valorar que los usuarios compren, no tanto que les guste algo m√°s o menos, tambi√©n 
es importante tenerlo en cuenta. 


Para probar nuestro modelo realizamos una conversi√≥n de nuestros datos nombre de juegos a diccionario de python para facilitar su visualizaci√≥n, 
ya que lo que nos llegar√° en √∫ltima instancia son los `game_id` junto con `user_id` de las recomendaciones para ese usuario. Tambi√©n realizamos 
un filtrado de juegos populares, ojo, no quiere decir que sean los que m√°s les gust√≥ al p√∫blico sino los que tienen m√°s puntuaciones. Luego 
ajustamos la columna de `user_id` con el id del usuario cuyas recomendaciones queramos conocer y aplicamos la funci√≥n `transform` del modelo
para realizar las predicciones. Luego ordenaremos las predicciones por puntuaci√≥n de mayor a menor y tomaremos solo 20 del total. 


![Captura desde 2023-03-12 17-44-59](https://user-images.githubusercontent.com/116188406/224559274-20271b57-aaa6-49a4-a661-41981d4f28fa.png)



Estas son las puntuaciones que ten√≠a por ejemplo este usuario con 9984689


![Captura desde 2023-03-12 17-39-04](https://user-images.githubusercontent.com/116188406/224558906-21a16497-e535-4d1a-b5a2-03c9f380f1d7.png)

Y estas fueron las recomendaciones. Podemos ver que recomienda juegos similares

![Captura desde 2023-03-12 17-40-04](https://user-images.githubusercontent.com/116188406/224558948-39b5e9b5-3b54-4360-b1dd-5da1072d56c9.png)

Una vez realizado el modelo y comprobado que funciona es hora de guardarlo para integrarlo en nuestra aplicaci√≥n. Este proceso es tan 
sencillo como ejecutar `model.save("nombre_deseado")`. Posteriormente se usar√° otra librer√≠a diferente para cargarlo. Esto genera una 
carpeta con los datos del modelo entrenado. 


##  6. Integraci√≥n del modelos en la aplicaci√≥n 

##  7. Aplicaci√≥n de Procesamiento del Lenguaje Natural: Chatbot con dialog flow 

##  8. Aplicaci√≥n Web: Dockerizaci√≥n y despliegue

##  9. Conclusiones





## Comenzando üöÄ

_Para comenzar a usar KnoxQuack se implementara un sencillo manual para que el usuario no se sienta desorientado a la hora de su uso._

## Despliegue üì¶

_El despliegue de esta aplicaci√≥n esta realizado en Streamlit._

## Construido con üõ†Ô∏è

### FRONT

### BACK

* Python

## Servicio de despliegue utilizado üñáÔ∏è

_El servicio de despliegue usado para esta ocasi√≥n es Streamlit, debido a su gu√≠a y accesibilidad bien expuesta para el usuario de forma que se pueda subir y desplegar con mayor facilidad._

Link de la aplicaci√≥n: https://aresonay-knoxquack-app-5jrn6s.streamlit.app/


## Autores ‚úíÔ∏è

* Ismael Armada Gonz√°lez
* √Ångel Ser√≥n M√°rquez
